{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames, Iowa Housing Data - Exploration and Preparation\n",
    "\n",
    "In this notebook, we conduct our exploratory data analysis (EDA) and prepare our data for modeling using linear regression. This notebook contains the following sections:\n",
    "- [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis-(EDA))\n",
    "- [Data Preparation](#Data-Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from general_functions import LeeFunctions as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in housing data files \n",
    "\n",
    "orig = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we look at what information is contained in our data sets, including data types, feature names and rudimentary statistics. From this, we determine which numerical variables are most closely correlated with our target variable, sale price. We use this exploration to select a group of features which we believe have the most predictive power, which will be used to create our final independent variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snake_case column names for ease of use. Create a new data feature [age] from the year sold and year built/remodeled features\n",
    "for frames in [orig,test]:\n",
    "    frames.columns = [col.lower().replace(' ','_') for col in frames.columns]\n",
    "    frames['age'] = frames['yr_sold'] - frames['year_remod/add']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set size: (2051, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pid</th>\n",
       "      <th>ms_subclass</th>\n",
       "      <th>ms_zoning</th>\n",
       "      <th>lot_frontage</th>\n",
       "      <th>lot_area</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lot_shape</th>\n",
       "      <th>land_contour</th>\n",
       "      <th>...</th>\n",
       "      <th>pool_area</th>\n",
       "      <th>pool_qc</th>\n",
       "      <th>fence</th>\n",
       "      <th>misc_feature</th>\n",
       "      <th>misc_val</th>\n",
       "      <th>mo_sold</th>\n",
       "      <th>yr_sold</th>\n",
       "      <th>sale_type</th>\n",
       "      <th>saleprice</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>130500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>220000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>109000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>174000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>138500</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id        pid  ms_subclass ms_zoning  lot_frontage  lot_area street alley  \\\n",
       "0  109  533352170           60        RL           NaN     13517   Pave   NaN   \n",
       "1  544  531379050           60        RL          43.0     11492   Pave   NaN   \n",
       "2  153  535304180           20        RL          68.0      7922   Pave   NaN   \n",
       "3  318  916386060           60        RL          73.0      9802   Pave   NaN   \n",
       "4  255  906425045           50        RL          82.0     14235   Pave   NaN   \n",
       "\n",
       "  lot_shape land_contour  ... pool_area pool_qc fence misc_feature misc_val  \\\n",
       "0       IR1          Lvl  ...         0     NaN   NaN          NaN        0   \n",
       "1       IR1          Lvl  ...         0     NaN   NaN          NaN        0   \n",
       "2       Reg          Lvl  ...         0     NaN   NaN          NaN        0   \n",
       "3       Reg          Lvl  ...         0     NaN   NaN          NaN        0   \n",
       "4       IR1          Lvl  ...         0     NaN   NaN          NaN        0   \n",
       "\n",
       "  mo_sold yr_sold sale_type  saleprice  age  \n",
       "0       3    2010       WD      130500    5  \n",
       "1       4    2009       WD      220000   12  \n",
       "2       1    2010       WD      109000    3  \n",
       "3       4    2010       WD      174000    3  \n",
       "4       3    2010       WD      138500   17  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first few rows of the data set, just to see what we're dealing with\n",
    "\n",
    "print('Training data set size:',orig.shape)\n",
    "orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lot_frontage: 330 null values\n",
      "alley: 1911 null values\n",
      "mas_vnr_type: 22 null values\n",
      "mas_vnr_area: 22 null values\n",
      "bsmt_qual: 55 null values\n",
      "bsmt_cond: 55 null values\n",
      "bsmt_exposure: 58 null values\n",
      "bsmtfin_type_1: 55 null values\n",
      "bsmtfin_sf_1: 1 null values\n",
      "bsmtfin_type_2: 56 null values\n",
      "bsmtfin_sf_2: 1 null values\n",
      "bsmt_unf_sf: 1 null values\n",
      "total_bsmt_sf: 1 null values\n",
      "bsmt_full_bath: 2 null values\n",
      "bsmt_half_bath: 2 null values\n",
      "fireplace_qu: 1000 null values\n",
      "garage_type: 113 null values\n",
      "garage_yr_blt: 114 null values\n",
      "garage_finish: 114 null values\n",
      "garage_cars: 1 null values\n",
      "garage_area: 1 null values\n",
      "garage_qual: 114 null values\n",
      "garage_cond: 114 null values\n",
      "pool_qc: 2042 null values\n",
      "fence: 1651 null values\n",
      "misc_feature: 1986 null values\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of null values in the data set. These features will have to have their null values removed or imputed later if they are to be included in the model\n",
    "\n",
    "lf.check_frame(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                saleprice\n",
      "garage_yr_blt    0.533922\n",
      "full_bath        0.537969\n",
      "year_remod/add   0.550370\n",
      "year_built       0.571849\n",
      "1st_flr_sf       0.618486\n",
      "total_bsmt_sf    0.628925\n",
      "garage_cars      0.648220\n",
      "garage_area      0.650270\n",
      "gr_liv_area      0.697038\n",
      "overall_qual     0.800207\n"
     ]
    }
   ],
   "source": [
    "# Find correlations among numerical values in comparison to our target variable, sales price, and show the top 10 features\n",
    "\n",
    "salecor = orig.corr()[['saleprice']].sort_values(by='saleprice', axis=0)\n",
    "print(salecor[-11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our correlation analysis, we selected a group of variables that we believe will predict sale price well. Certain groups of features were represented by a single variable due to the high level of dependency between them. For example, only garage area was selected, since the number of cars the garage could hold would likely be highly correlated to the size. From this, we selected the following numerical values: \n",
    "- Above ground living area (gr_liv_area)\n",
    "- Overall quality (overall_qual)\n",
    "- Age\n",
    "- Total basement area (total_bsmt_sf)\n",
    "- Garage area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Create seaborn pairplot of our numerical variables against sale price in order to see how these relationships look in isolation. This helps us identify outliers in each category\n",
    "\n",
    "sns.pairplot(data=orig, y_vars=['saleprice'], x_vars=['gr_liv_area','overall_qual','age','total_bsmt_sf','garage_area','totrms_abvgrd']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/sns_pairplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the pairplot, we identified several potential outliers (circled in red). As suggested by the [original data set description](http://jse.amstat.org/v19n3/decock/DataDocumentation.txt), we believe removing houses with total living areas greater than 4,000 sq. ft. will not adversely affect our model. We apply a similar rationale for removing the data points with extremely large total basement areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier data points with extremely large living and basement areas. Once these rows have been dropped, we can then create our data sets for model fitting\n",
    "\n",
    "orig.drop(orig[orig['gr_liv_area'] > 4000].index, inplace=True)\n",
    "orig.drop(orig[orig['total_bsmt_sf'] > 4000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-numerical values, we chose two features based on our general experience that we believe have the greatest impact on the value of a house: **location** and the **type** of house. These correspond to the features _neighborhood_ and *bldg_type*, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "To use our selected data to create a regression model, we first have to make sure the data is cleaned and organized such that the fit can be applied. Our first step was to organize the selected features into several categories, as described below\n",
    "\n",
    "|Name|Description|\n",
    "|---|---|\n",
    "nums|Variables whose values must be numeric, either int or float. Dictionary includes the minimum and maximum expected values for the variable\n",
    "cats|Variables that are categorical or ordinal in nature. Types can be both numerical or strings. Variables in this category default to have missing values imputed to the mode of the variable\n",
    "median|Variables where it is decided that the proper imputation method is by replacing null values with the training data median. This is for variables where having a zero value would be illogical, such as having a house with 0 sq. ft. of living area\n",
    "blanks|Variables where it is decided that it is acceptable to have a 0 value. For example, it is possible for a house to have a 0 garage area (no garage)\n",
    "feature|Total feature list, which is the set union of the cats and nums lists\n",
    "\n",
    "The data sets were then cleaned of null values by imputing missing values using the methods described in each of the categories above. Features in the nums category were checked to ensure they contained only numeric values and that these values fell within accepted ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize variables as described above. Create model data sets which contains only our variables of interest, as well as our target\n",
    "# vector (orig['saleprice']), and wrap in a list to be passed to our modeling notebook later\n",
    "\n",
    "nums = {'overall_qual':[1,10],\n",
    "        'gr_liv_area':[0,'none'],\n",
    "        'age':[0,300],\n",
    "        'total_bsmt_sf':[0,'none'],\n",
    "        'garage_area':[0,'none']}\n",
    "\n",
    "cats = ['bldg_type', 'neighborhood', 'overall_qual']\n",
    "median = ['age','gr_liv_area']\n",
    "blanks = ['total_bsmt_sf','garage_area']\n",
    "features = set(list(nums) + cats)\n",
    "\n",
    "datasets = [orig.copy()[features], test.copy()[features], orig['saleprice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0:\n",
      "Feature [total_bsmt_sf]: 1 null values converted to 0\n",
      "Feature [garage_area]: 1 null values converted to 0\n",
      "No null values in data set\n",
      "Checking for numerical type mismatches in features: ['overall_qual', 'gr_liv_area', 'age', 'total_bsmt_sf', 'garage_area']\n",
      "No type mismatches found\n",
      "Checking for out of range values in features: ['overall_qual', 'gr_liv_area', 'age', 'total_bsmt_sf', 'garage_area']\n",
      "Feature [age] minimum values corrected\n",
      "\n",
      "\n",
      "Frame 1:\n",
      "No null values in data set\n",
      "Checking for numerical type mismatches in features: ['overall_qual', 'gr_liv_area', 'age', 'total_bsmt_sf', 'garage_area']\n",
      "No type mismatches found\n",
      "Checking for out of range values in features: ['overall_qual', 'gr_liv_area', 'age', 'total_bsmt_sf', 'garage_area']\n",
      "No out of range values in selected features\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean our data sets to impute missing values and check to make sure our features are of the correct type so that we don't run into errors during the modeling process. Corrections\n",
    "# (or lack thereof) are printed as outputs. For a more detailed explanation of each of the functions called here, consult the documentation in the general function .py file\n",
    "# Create dummy columns for categorical variables\n",
    "\n",
    "for x in range(2):\n",
    "    frames = datasets[x]\n",
    "    print(f'Frame {x}:')\n",
    "    lf.impute_frame(frames, modes=cats, medians=median, zeroes=blanks, reference=datasets[0])\n",
    "    lf.check_frame(frames, numericals = nums)\n",
    "    lf.check_range(frames, numericals = nums, correct=True)\n",
    "    lf.collapse_ordinal(frames, 'overall_qual', [1,10], 5)\n",
    "    frames = pd.get_dummies(frames, columns=cats, drop_first=True)\n",
    "    datasets[x] = frames    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When creating dummy columns, if values are missing in one of the data sets, it's possible to not create the same number of columns in one of the data sets. This function checks\n",
    "# the columns of both the test and training data and ensures that they are the same and aligned\n",
    "\n",
    "datasets[0], datasets[1] = lf.match_columns(datasets[0], datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%store datasets\n",
    "\n",
    "# Store our cleaned and prepped data sets to pass to our modeling notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
